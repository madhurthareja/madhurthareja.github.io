---
layout: about
title: About
permalink: /
subtitle: Undergraduate Researcher

profile:
  align: right
  image: prof_pic.png
  image_circular: false
  more_info: >
    <p style="font-size: 12px">madhurthareja1105@gmail.com</p>
    <p style="font-size: 12px"><a href="https://github.com/madhurthareja" target="_blank">github.com/madhurthareja</a></p>
    <p style="font-size: 12px"><a href="https://www.linkedin.com/in/madhurthareja/" target="_blank">linkedin.com/in/madhurthareja</a></p>

news: false
selected_papers: false
social: false
---
{% assign cv_path = "/assets/pdf/Madhur_Thareja_Resume.pdf" %}

## About me

I'm Madhur Thareja, a dual-major undergraduate in Electronic Systems (IIT Madras) and Computer Science (BITS Pilani).
My research sits at the intersection of multimodal perception, grounded language agents, and hardware-aware deployment.
I care about building systems that can justify their decisions and still run on constrained platforms.

<p><a href="{{ cv_path }}" target="_blank" rel="noopener">Download my full CV →</a></p>

## Current roles

- **Researcher, XuLab @ Carnegie Mellon University (Aug 2025 – present)** — Multimodal medical reasoning (MediLLM/MMedRAG),
  retrieval-augmented diagnosis flows, and uncertainty reporting.
- **Research Intern, AIISC @ UofSC (Jun 2025 – present)** — Development of NeuroSymbolic Agents from scratch, evaluating them for the 14 foundational priciples of C3AN - Custom, Compact, Composite and NeuroSymbolic Framework for Enterprise AI applications ranging from the domain of mental health, education, finance.

## Research focus

1. **Clinical & scientific reasoning** — Aligning visual-language models with structured lab context so diagnostic copilots stay grounded.
2. **Human-in-the-loop tutoring** — Multi-agent PAL stack that mixes VLM grounding with reinforcement learning for adaptive feedback.
3. **Edge autonomy** — RTL-to-GDSII implementations of RISC-V cores, sensor fusion for autonomous wheelchairs, and OpenVINO RVV enablement.

<!-- ## Selected internships

- **Research Intern, LivecellX (2025)** — Combined diffusion refinements with Ultrack to stabilize single-cell lineage tracing
  and shipped evaluation tooling shared across the lab.
- **Research Fellow, Samsung Semiconductor Chip Design Studio (Jan–Feb 2025)** — Closed RTL→GDSII for single-cycle and pipelined
  RISC-V microarchitectures, integrated UART/PWM/GPIO IP for robotics demos, and placed #2 nationally.
- **Autonomous Systems Lead, IIT Madras Smart Wheelchair (2024)** — Architected LiDAR + stereo + GPS/IMU fusion, built distributed
  control loops, and deployed safe teleoperation fallbacks for hospital pilots. -->

## Motivation

I want autonomy that explains itself: agents that can cite the evidence behind a diagnosis, quantify their uncertainty,
and still execute efficiently on edge hardware. If you work on multimodal agents, medical perception, or embedded deployments,
I'm always up for a conversation.
